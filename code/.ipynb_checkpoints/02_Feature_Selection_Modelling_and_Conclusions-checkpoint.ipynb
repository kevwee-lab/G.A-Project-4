{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "- [Reiteration of Problem statement](#Reiteration-of-Problem-statement)\n",
    "- [Methodology](#Methodology)\n",
    "- [Preprocessing](#Preprocessing)\n",
    "- [Model with Base Features](#Model-with-Base-Features)\n",
    "- [Polynomial Features](#Polynomial-Features)\n",
    "- [SMOTE](#SMOTE)\n",
    "- [Model Evaluaton](#Model-Evaluaton)\n",
    "- [Cost-Benefit Analysis of Spraying](#Cost-Benefit-Analysis-of-Spraying)\n",
    "- [Conclusions](#Conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reiteration of Problem Statement\n",
    "\n",
    "In view of the recent epidemic in Windy City of Chicago state affecting the state population, we aim to build a classifier model to make predictions on the possibility of West Nile Virus occurence on various locations of interest, which could be used to aid the deployment of pesticides in the fight for public health and safety. \n",
    "The model would be build using collected data related to mosquito population from the surveillance and control system setup by Deparment of Public Health. \n",
    "\n",
    "In addition, a cost-benefit analysis would be conducted on the cost benefits for the use of pesticides as a response in managing the epidemic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "\n",
    "The methodology involved in the modelling process can be described as follows:\n",
    "\n",
    "**1) Preprocessing and direct modelling**\n",
    " - Converting the data into suitable format for modelling\n",
    " - Applying baseline classifier to set baseline metric for comparison with of other models\n",
    " - Applying pearson's correlation with 3 different cutoff points for correlation (> 0.01, > 0.05 and > 0.1) to identify correlated features while selecting useful features for direct modelling. Models considered are listed in point 4\n",
    " \n",
    "**2) Feature Expansion**\n",
    " - Generate polynomial and interaction features to increase the number of features involving cross terms with a degree 2 to prevent excessive feature expansion and scaling the data subsequently\n",
    " \n",
    "**3) Feature Selection**\n",
    " - A) Recursive Feature Selection to select ideal features for modelling\n",
    " - B) Principal Component Analysis to reduce dimensionality of features by using principal component features generated from the data features\n",
    " \n",
    "**4) Modelling, hyperparameter tuning and best model selection**\n",
    "\n",
    "- Models considered with hyperparameters dictated by gridsearch\n",
    " - A) **Support Vector Classifier**: Effective in high dimensional spaces. Uses a subset of training points in the decision function.\n",
    " - B) **Logistic Regression**: Effective in binary classification.\n",
    " - C) **Gradient boost**: Produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. Uses gradient descent algorithm.\n",
    " - D) **Xg boost**: Similar to gradient boost, but it uses a more regularized model formalization to control over-fitting.\n",
    " - E) **Random Forest**: Constructs decision trees at training time and outputting the class that is the mode of the classes.\n",
    " - F) **Extra Trees**: Similar to Random Forest. However, the splits of the trees in the Random Forest are deterministic. It is random for extratrees.\n",
    "\n",
    "- Subsequently finetune the parameters, and select the best model based on ROC-AUC score, precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../assets/train_combined.csv', parse_dates=['date'])\n",
    "test = pd.read_csv('../assets/test_combined.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "(just standard scaler first, later section then poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Base Features\n",
    "\n",
    ".."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Features\n",
    "\n",
    "see if can improve metrics..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of Features by Correlation\n",
    "\n",
    "(find the proper term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE\n",
    "\n",
    "to resolve class imbalance ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "(without final conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost-Benefit Analysis of Spraying\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "insights/findings from evaluation & CBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
